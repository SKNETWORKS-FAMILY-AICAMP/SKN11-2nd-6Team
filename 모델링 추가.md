# SKN11-2nd-6Team
# 팀명: **6조**
---

## 팀원 소개

|[@홍성욱](https://github.com/Sung-WookHong)|[@이혜성](https://github.com/comet39)|[@이채은](https://github.com/chaeeunlee05)|[@김성지](https://github.com/kimseoungji0801)|[@백미송](https://github.com/misong-hub)|
|------|------|------|------|------|
| <img src="https://github.com/user-attachments/assets/df0d3172-e97e-4909-8c53-dbb5ee137713" width="200"/>|<img src="https://github.com/user-attachments/assets/9c95cb5d-a8e2-4716-a7a4-7278aee484d1" width="200"/>  | <img src="https://github.com/user-attachments/assets/2dc83746-b3a4-45a8-96d3-36a458222cc1" width="200"/> |  <img src="https://github.com/user-attachments/assets/108ea96c-cb56-42fc-90cb-0d2c833c0fd2" width="200"/> | <img src="https://github.com/user-attachments/assets/27d29763-0f6a-4b17-8151-e5654c407e7d" width="200"/> |

# 프로젝트명 : 대학교 수강 이탈 예측 모델링

## 목차 

### 1. 🎯 프로젝트 개요
### 2. 🧹 데이터 전처리
   Feature Importance 시각화 추가하기
### 3. 📊 탐색적 데이터 분석 (EDA)
- StandardScaler 적용 (정규화) 추가하기
### 4. ⚙️ 모델링
### 5. 📈 모델 평가 (최종)
- 오버피팅 여부 확인
### 6. 💡 인사이트 및 결론
- 이탈자의 주요 특성 요약
- 가장 영향력 있는 변수 분석 (예: 점수 편차↑, 제출률↓, 지각률↑)
- 이탈 위험군 조기 예측 가능성
- 실무 적용 시나리오 제안


# 1. 프로젝트 개요

## 📅 개발 기간
**2025년 3월 31일** ~ **2025년 4월 1일**

## 📌 프로젝트 목표
- 대학교 수강생들의 이탈(수강 취소) 여부를 조기 예측하여 학습 지원 및 개입 방안 마련<br/>
- 학생들의 과제 제출 패턴 및 성적 특성을 분석하여 이탈 징후를 파악<br/>
- 머신러닝 모델을 통해 이탈 위험군을 사전에 식별하고 예측 성능을 극대화<br/>

## 🌟 기대 효과
- 이탈 가능성 높은 학생을 조기에 파악함으로써 맞춤형 학습 지원 제공 가능<br/>
- 교육 기관의 학업 성공률 및 수료율 향상<br/>
- *과제 기반 행동 데이터만으로도 충분한 예측 성능을 확보함으로써 효율적인 데이터 수집 및 분석 체계 구축 가능*<br/>

## 🛠️ **접근 방식**
- Open University의 실제 데이터셋(OULAD) 활용
- 과제 제출율, 과제 점수 분위수, 평균 성적 Z-점수 등을 주요 피처로 활용
- 수강생의 이탈 여부(Withdrawn) 를 타겟 변수로 설정
- 데이터 전처리 및 피처 엔지니어링을 통해 날짜 정보, 제출 시기, 등록 시기 등을 범주화하여 반영
- Logistic Regression, Random Forest 등의 분류 모델을 적용
-최종적으로 모델 성능을 평가하고 이탈 예측에 가장 영향력 있는 변수 분석
   
## 🎯 **타겟 변수**: **`수강취소여부`** 
- Yes → 수강을 취소한 학생 (이탈)
- No → 수강을 완료한 학생 (비이탈)


## 📂 데이터셋
[Open University Learning Analytics Dataset (OULAD)](https://analyse.kmi.open.ac.uk/#open-dataset) <br/>
오픈 유니버시티(Open University)에서 공개한 영국 Open University 학생들의 **온라인 학습 행동 및 이탈 관련 데이터셋**.<br/>
학습자의 활동, 평가 성적, 이탈 여부 등 **교육 분석(learning analytics)** 연구에 유용하게 쓰이는 대표적인 공개 데이터

### 데이터 구성 (5개의 CSV 파일)

1. `assessments.csv` : 각 강의의 과제(평가) 관련 정보 <br/>
2. `studentAssessment.csv`: 학생들의 과제 제출 및 성적 정보 <br/>
3. `courses.csv`: 개설된 각 강의(course)에 대한 정보 <br/>
4. `studentInfo.csv` : 각 학생의 인구통계학적 정보와 수강 결과 <br/>
5. `studentRegistration.csv`: 학생들의 수강 신청 및 이탈(취소) 정보 <br/>

    ↪️ **`merged_data.csv`** : 분석과 모델링에 필요한 주요 정보를 포함한 최종 분석용 데이터셋.  <br/>
   -5개의 csv 파일을 `학생 ID(id_student)`, `과목 코드(code_module)`, `학기(code_presentation)`를 기준으로 병합 <br/>
   ![image](https://github.com/user-attachments/assets/4628b792-cfee-41a1-8ace-aa20a437b605)


## 🔧 기술 스택

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white" style="display: inline-block; margin: 5px;">
  <img src="https://img.shields.io/badge/pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" style="display: inline-block; margin: 5px;">
  <img src="https://img.shields.io/badge/numpy-013243?style=for-the-badge&logo=NumPy&logoColor=white" style="display: inline-block; margin: 5px;">
</p>


# 4. 모델링

### ⚠️**클래스 불균형 문제**
![image](https://github.com/user-attachments/assets/88a00bb3-78b2-4786-8298-b86bcd0f02d2)
```python
voting_clf.fit(X_train_scaled, y_train)
y_pred = voting_clf.predict(X_test_scaled)
```
![image](https://github.com/user-attachments/assets/96bfc0b6-2686-4d2b-bf50-06ded91dba83)
- **클래스 0 (비이탈자)** 는 잘 맞추고 있음 (recall=1.00).
- **클래스 1 (이탈자)** 는 recall이 0.28, 즉 이탈자를 정확히 잡아내지 못하고 있음.
- 전반적으로 **정확도 95%** 는 높지만, 이는 다수 클래스인 0에 의존한 착시.

## ⬆️ 오버샘플링
### ⚙️ 전처리 요약
- 클래스 불균형 처리: SMOTE를 통해 **이탈자 수(1)** 를 오버샘플링하여 균형 잡힌 학습 데이터셋 구성
- 정규화: StandardScaler를 이용해 모든 특성값을 표준 정규분포(평균=0, 표준편차=1)로 변환
- Train/Test Split: train_test_split()을 사용하여 8:2 비율, stratify 옵션으로 이탈 여부 비율 유지하며 데이터 분할<br/>
   ※ Pipeline을 활용해 SMOTE 적용 → 모델 학습을 일괄 처리하여 코드 재사용성과 확장성 향상
```python
smote=SMOTE(random_state=42)
X_resample,y_resample = smote.fit_resample(X_train_scaled,y_train)
```
  ![image](https://github.com/user-attachments/assets/40a2a50a-11a4-4547-8c21-fedd36202885)
- recall이 0.28 → 0.52로 크게 상승 → **이탈자를 훨씬 더 많이 잡아냄.**
- precision은 줄었지만 이는 이탈자 예측을 더 시도했기 때문에 자연스러운 현상.
- f1-score도 올라서 **균형 잡힌 예측 성능 향상.**


## ⬇️ 언더샘플링
### ⚙️ 전처리 요약
- 클래스 불균형 처리: **언더샘플링**으로 **이탈자 수(1)** 에 맞춰 비이탈자 수 조정
- 원핫 인코딩: 범주형 변수 변환
- Train/Test Split: train_test_split() 사용하여 **8:2 비율**로 분할

### 1. 앙상블 (기본)
- Voting 방식: Hard Voting
→ 로지스틱 회귀, DecisionTreeClassifier, XGBoost의 다수결 투표로 최종 예측을 결정하는 기본 앙상블 방식.
```python
VotingClassifier(
    estimators=[
        ('lr_clf', LogisticRegression()),
        ('dt_clf', DecisionTreeClassifier()),
        ('xgb_clf', XGBClassifier())
    ],
    voting='hard'
)
```
![image](https://github.com/user-attachments/assets/41c0477d-97c2-4ace-9722-1390e96d9634)

### 2. 앙상블 + GridSearchCV 
- Voting 방식: Soft Voting + 하이퍼파라미터 튜닝(GridSearchCV)
→ 각 모델을 GridSearchCV로 튜닝한 후 soft voting 방식으로 예측 확률 평균을 기반으로 최종 예측을 수행.
```python
# 4. Logistic Regression 튜닝
lr_param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l2'],
    'solver': ['lbfgs'],
    'max_iter': [100, 500, 1000]
}
lr_grid = GridSearchCV(LogisticRegression(), lr_param_grid, scoring='f1', cv=3, verbose=1, n_jobs=-1)
lr_grid.fit(X_train, y_train)
best_lr = lr_grid.best_estimator_

# 5. Decision Tree 튜닝
dt_param_grid = {
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'criterion': ['gini', 'entropy']
}
dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_param_grid, scoring='f1', cv=3, verbose=1, n_jobs=-1)
dt_grid.fit(X_train, y_train)
best_dt = dt_grid.best_estimator_

# 6. XGBoost 튜닝
xgb_param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0]
}
xgb_grid = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42), xgb_param_grid, scoring='f1', cv=3, verbose=1, n_jobs=-1)
xgb_grid.fit(X_train, y_train)
best_xgb = xgb_grid.best_estimator_
```
![image](https://github.com/user-attachments/assets/3bb140d3-47cf-4bc7-a588-c5ac61934c04)


### 3. 앙상블 + RandomizedSearchCV
- Voting 방식: Soft Voting + 하이퍼파라미터 튜닝(RandomizedSearchCV)
→ 모델별로 랜덤 탐색 기반 튜닝(RandomizedSearchCV) 후 soft voting으로 예측 확률 평균을 활용하여 예측.
```python
# 4. RandomizedSearchCV - Logistic Regression
lr_param_dist = {
    'C': uniform(0.01, 10),
    'penalty': ['l2'],
    'solver': ['lbfgs'],
    'max_iter': [100, 300, 500, 1000]
}
lr_random = RandomizedSearchCV(
    estimator=LogisticRegression(),
    param_distributions=lr_param_dist,
    n_iter=20,
    scoring='f1',
    cv=3,
    verbose=1,
    n_jobs=-1,
    random_state=42
)
lr_random.fit(X_train, y_train)
best_lr = lr_random.best_estimator_

# 5. RandomizedSearchCV - Decision Tree
dt_param_dist = {
    'max_depth': randint(3, 20),
    'min_samples_split': randint(2, 20),
    'criterion': ['gini', 'entropy']
}
dt_random = RandomizedSearchCV(
    estimator=DecisionTreeClassifier(random_state=42),
    param_distributions=dt_param_dist,
    n_iter=30,
    scoring='f1',
    cv=3,
    verbose=1,
    n_jobs=-1,
    random_state=42
)
dt_random.fit(X_train, y_train)
best_dt = dt_random.best_estimator_

# 6. RandomizedSearchCV - XGBoost
xgb_param_dist = {
    'n_estimators': randint(50, 300),
    'max_depth': randint(3, 15),
    'learning_rate': uniform(0.01, 0.3),
    'subsample': uniform(0.7, 0.3),
    'colsample_bytree': uniform(0.7, 0.3)
}
xgb_random = RandomizedSearchCV(
    estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    param_distributions=xgb_param_dist,
    n_iter=30,
    scoring='f1',
    cv=3,
    verbose=1,
    n_jobs=-1,
    random_state=42
)
xgb_random.fit(X_train, y_train)
best_xgb = xgb_random.best_estimator_
```
![image](https://github.com/user-attachments/assets/f4610204-6c05-45a9-9fbe-74a4def9736b)

### 4. 앙상블 + RandomizedSearchCV + LogisticRegression 정규화

```python
lr_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', LogisticRegression())
])
lr_param_dist = {
    'model__C': uniform(0.01, 10),
    'model__penalty': ['l2'],
    'model__solver': ['lbfgs'],
    'model__max_iter': [100, 300, 500, 1000]
}
```
![image](https://github.com/user-attachments/assets/72e7d5b1-d06e-4c7b-a7fa-045eb5446f54)



