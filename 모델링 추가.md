### 변수별 행동 분석 시각화: `과제 점수 비중 assessment_weight` (예시)
![스크린샷 2025-04-01 130619](https://github.com/user-attachments/assets/676ca479-e52a-4f8a-a94f-4718dc98e213)

- 데이터가 수직적으로 랜덤하게 분포해 있어, 의미 있는 경향성이 없다는 것을 시각적으로 확인 가능
- assessment_weight 분포는 Dropout 여부(0 vs 1)에 상관없이 유사

- 학생의 이탈 여부는 단일 수치 변수로 설명되지 않으며, 학생의 행동 기반 요인들은 매우 **랜덤하게 작용함.**
- 본 데이터셋 내 다른 변수들과 마찬가지로 **단편적인 변수만으로 이탈을 예측하는 데 한계가 있음**을 시사하며, 보다 **복합적인 요인들의 통합 분석이 필요함.**




















## 팀원 소개

|[@홍성욱](https://github.com/Sung-WookHong)|[@이혜성](https://github.com/comet39)|[@이채은](https://github.com/chaeeunlee05)|[@김성지](https://github.com/kimseoungji0801)|[@백미송](https://github.com/misong-hub)|
|------|------|------|------|------|
| <img src="https://github.com/user-attachments/assets/df0d3172-e97e-4909-8c53-dbb5ee137713" width="200"/>|<img src="https://github.com/user-attachments/assets/9c95cb5d-a8e2-4716-a7a4-7278aee484d1" width="200"/>  | <img src="https://github.com/user-attachments/assets/2dc83746-b3a4-45a8-96d3-36a458222cc1" width="200"/> |  <img src="https://github.com/user-attachments/assets/108ea96c-cb56-42fc-90cb-0d2c833c0fd2" width="200"/> | <img src="https://github.com/user-attachments/assets/27d29763-0f6a-4b17-8151-e5654c407e7d" width="200"/> |










# 프로젝트명 : 대학교 수강 이탈 예측 모델링






## 목차 

### 1. 🎯 프로젝트 개요
### 2. 🧹 데이터 전처리
   Feature Importance 시각화 추가하기
### 3. 📊 탐색적 데이터 분석 (EDA)
- StandardScaler 적용 (정규화) 추가하기
### 4. ⚙️ 모델링
### 5. 📈 모델 평가 (최종)
- 오버피팅 여부 확인
### 6. 💡 인사이트 및 결론
- 이탈자의 주요 특성 요약
- 가장 영향력 있는 변수 분석 (예: 점수 편차↑, 제출률↓, 지각률↑)
- 이탈 위험군 조기 예측 가능성
- 실무 적용 시나리오 제안


# 1. 프로젝트 개요

## 📅 개발 기간
**2025년 3월 31일** ~ **2025년 4월 1일**

## 📌 프로젝트 목표
- 대학교 수강생들의 이탈(수강 취소) 여부를 조기 예측하여 학습 지원 및 개입 방안 마련<br/>
- 학생들의 과제 제출 패턴 및 성적 특성을 분석하여 이탈 징후를 파악<br/>
- 머신러닝 모델을 통해 이탈 위험군을 사전에 식별하고 예측 성능을 극대화<br/>

## 🌟 기대 효과
- 이탈 가능성 높은 학생을 조기에 파악함으로써 맞춤형 학습 지원 제공 가능<br/>
- 교육 기관의 학업 성공률 및 수료율 향상<br/>
- *과제 기반 행동 데이터만으로도 충분한 예측 성능을 확보함으로써 효율적인 데이터 수집 및 분석 체계 구축 가능*<br/>

## 🛠️ **접근 방식**
- Open University의 실제 데이터셋(OULAD) 활용
- 과제 제출율, 과제 점수 분위수, 평균 성적 Z-점수 등을 주요 피처로 활용
- 수강생의 이탈 여부(Withdrawn) 를 타겟 변수로 설정
- 데이터 전처리 및 피처 엔지니어링을 통해 날짜 정보, 제출 시기, 등록 시기 등을 범주화하여 반영
- Logistic Regression, Random Forest 등의 분류 모델을 적용
-최종적으로 모델 성능을 평가하고 이탈 예측에 가장 영향력 있는 변수 분석
   
## 🎯 **타겟 변수**: **`수강취소여부`** 
- Yes → 수강을 취소한 학생 (이탈)
- No → 수강을 완료한 학생 (비이탈)


## 📂 데이터셋
[Open University Learning Analytics Dataset (OULAD)](https://analyse.kmi.open.ac.uk/#open-dataset) <br/>
오픈 유니버시티(Open University)에서 공개한 영국 Open University 학생들의 **온라인 학습 행동 및 이탈 관련 데이터셋**.<br/>
학습자의 활동, 평가 성적, 이탈 여부 등 **교육 분석(learning analytics)** 연구에 유용하게 쓰이는 대표적인 공개 데이터

### 데이터 구성 (5개의 CSV 파일)

1. `assessments.csv` : 각 강의의 과제(평가) 관련 정보 <br/>
2. `studentAssessment.csv`: 학생들의 과제 제출 및 성적 정보 <br/>
3. `courses.csv`: 개설된 각 강의(course)에 대한 정보 <br/>
4. `studentInfo.csv` : 각 학생의 인구통계학적 정보와 수강 결과 <br/>
5. `studentRegistration.csv`: 학생들의 수강 신청 및 이탈(취소) 정보 <br/>

    ↪️ **`merged_data.csv`** : 분석과 모델링에 필요한 주요 정보를 포함한 최종 분석용 데이터셋.  <br/>
   -5개의 csv 파일을 `학생 ID(id_student)`, `과목 코드(code_module)`, `학기(code_presentation)`를 기준으로 병합 <br/>
   ![image](https://github.com/user-attachments/assets/4628b792-cfee-41a1-8ace-aa20a437b605)


## 🔧 기술 스택

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white" style="display: inline-block; margin: 5px;">
  <img src="https://img.shields.io/badge/pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" style="display: inline-block; margin: 5px;">
  <img src="https://img.shields.io/badge/numpy-013243?style=for-the-badge&logo=NumPy&logoColor=white" style="display: inline-block; margin: 5px;">
</p>


# 4. 모델링

### ⚠️**클래스 불균형 문제**
![image](https://github.com/user-attachments/assets/88a00bb3-78b2-4786-8298-b86bcd0f02d2)
```python
voting_clf.fit(X_train_scaled, y_train)
y_pred = voting_clf.predict(X_test_scaled)
```
![image](https://github.com/user-attachments/assets/96bfc0b6-2686-4d2b-bf50-06ded91dba83)
- **클래스 0 (비이탈자)** 는 잘 맞추고 있음 (recall=1.00).
- **클래스 1 (이탈자)** 는 recall이 0.28, 즉 이탈자를 정확히 잡아내지 못하고 있음.
- 전반적으로 **정확도 95%** 는 높지만, 이는 다수 클래스인 0에 의존한 착시.

## ⬆️ 오버샘플링
### ⚙️ 전처리 요약
- 클래스 불균형 처리: SMOTE를 통해 **이탈자 수(1)** 를 오버샘플링하여 균형 잡힌 학습 데이터셋 구성
- 정규화: StandardScaler를 이용해 모든 특성값을 표준 정규분포(평균=0, 표준편차=1)로 변환
- Train/Test Split: train_test_split()을 사용하여 8:2 비율, stratify 옵션으로 이탈 여부 비율 유지하며 데이터 분할<br/>
   ※ Pipeline을 활용해 SMOTE 적용 → 모델 학습을 일괄 처리하여 코드 재사용성과 확장성 향상
```python
smote=SMOTE(random_state=42)
X_resample,y_resample = smote.fit_resample(X_train_scaled,y_train)
```
  ![image](https://github.com/user-attachments/assets/40a2a50a-11a4-4547-8c21-fedd36202885)
- recall이 0.28 → 0.52로 크게 상승 → **이탈자를 훨씬 더 많이 잡아냄.**
- precision은 줄었지만 이는 이탈자 예측을 더 시도했기 때문에 자연스러운 현상.
- f1-score도 올라서 **균형 잡힌 예측 성능 향상.**


## ⬇️ 언더샘플링
### ⚙️ 전처리 요약
- 클래스 불균형 처리: **언더샘플링**으로 **이탈자 수(1)** 에 맞춰 비이탈자 수 조정
- 원핫 인코딩: 범주형 변수 변환
- Train/Test Split: train_test_split() 사용하여 **8:2 비율**로 분할

### 1. 앙상블 (기본)
- Voting 방식: Hard Voting
→ 로지스틱 회귀, DecisionTreeClassifier, XGBoost의 다수결 투표로 최종 예측을 결정하는 기본 앙상블 방식.
```python
VotingClassifier(
    estimators=[
        ('lr_clf', LogisticRegression()),
        ('dt_clf', DecisionTreeClassifier()),
        ('xgb_clf', XGBClassifier())
    ],
    voting='hard'
)
```
![image](https://github.com/user-attachments/assets/41c0477d-97c2-4ace-9722-1390e96d9634)

### 2. 앙상블 + GridSearchCV 
- Voting 방식: Soft Voting + 하이퍼파라미터 튜닝(GridSearchCV)
→ 각 모델을 GridSearchCV로 튜닝한 후 soft voting 방식으로 예측 확률 평균을 기반으로 최종 예측을 수행.
```python
# 4. Logistic Regression 튜닝
lr_param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l2'],
    'solver': ['lbfgs'],
    'max_iter': [100, 500, 1000]
}
lr_grid = GridSearchCV(LogisticRegression(), lr_param_grid, scoring='f1', cv=3, verbose=1, n_jobs=-1)
lr_grid.fit(X_train, y_train)
best_lr = lr_grid.best_estimator_

# 5. Decision Tree 튜닝
dt_param_grid = {
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'criterion': ['gini', 'entropy']
}
dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_param_grid, scoring='f1', cv=3, verbose=1, n_jobs=-1)
dt_grid.fit(X_train, y_train)
best_dt = dt_grid.best_estimator_

# 6. XGBoost 튜닝
xgb_param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0]
}
xgb_grid = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42), xgb_param_grid, scoring='f1', cv=3, verbose=1, n_jobs=-1)
xgb_grid.fit(X_train, y_train)
best_xgb = xgb_grid.best_estimator_
```
![image](https://github.com/user-attachments/assets/3bb140d3-47cf-4bc7-a588-c5ac61934c04)


### 3. 앙상블 + RandomizedSearchCV
- Voting 방식: Soft Voting + 하이퍼파라미터 튜닝(RandomizedSearchCV)
→ 모델별로 랜덤 탐색 기반 튜닝(RandomizedSearchCV) 후 soft voting으로 예측 확률 평균을 활용하여 예측.
```python
# 4. RandomizedSearchCV - Logistic Regression
lr_param_dist = {
    'C': uniform(0.01, 10),
    'penalty': ['l2'],
    'solver': ['lbfgs'],
    'max_iter': [100, 300, 500, 1000]
}
lr_random = RandomizedSearchCV(
    estimator=LogisticRegression(),
    param_distributions=lr_param_dist,
    n_iter=20,
    scoring='f1',
    cv=3,
    verbose=1,
    n_jobs=-1,
    random_state=42
)
lr_random.fit(X_train, y_train)
best_lr = lr_random.best_estimator_

# 5. RandomizedSearchCV - Decision Tree
dt_param_dist = {
    'max_depth': randint(3, 20),
    'min_samples_split': randint(2, 20),
    'criterion': ['gini', 'entropy']
}
dt_random = RandomizedSearchCV(
    estimator=DecisionTreeClassifier(random_state=42),
    param_distributions=dt_param_dist,
    n_iter=30,
    scoring='f1',
    cv=3,
    verbose=1,
    n_jobs=-1,
    random_state=42
)
dt_random.fit(X_train, y_train)
best_dt = dt_random.best_estimator_

# 6. RandomizedSearchCV - XGBoost
xgb_param_dist = {
    'n_estimators': randint(50, 300),
    'max_depth': randint(3, 15),
    'learning_rate': uniform(0.01, 0.3),
    'subsample': uniform(0.7, 0.3),
    'colsample_bytree': uniform(0.7, 0.3)
}
xgb_random = RandomizedSearchCV(
    estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    param_distributions=xgb_param_dist,
    n_iter=30,
    scoring='f1',
    cv=3,
    verbose=1,
    n_jobs=-1,
    random_state=42
)
xgb_random.fit(X_train, y_train)
best_xgb = xgb_random.best_estimator_
```
![image](https://github.com/user-attachments/assets/f4610204-6c05-45a9-9fbe-74a4def9736b)

### 4. 앙상블 + RandomizedSearchCV + LogisticRegression 정규화

```python
lr_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', LogisticRegression())
])
lr_param_dist = {
    'model__C': uniform(0.01, 10),
    'model__penalty': ['l2'],
    'model__solver': ['lbfgs'],
    'model__max_iter': [100, 300, 500, 1000]
}
```
![image](https://github.com/user-attachments/assets/72e7d5b1-d06e-4c7b-a7fa-045eb5446f54)


## 모델 시각화

### 1. 1. Logistic Regression - Feature Importance : (각 피처가 학생 이탈에 얼마나 영향을 미쳤는지)
![Image](https://github.com/user-attachments/assets/a9dcd180-2285-4f39-96ce-537bb2394019)

### **✅ 가장 큰 영향력을 가진 피처들** 
### 📈 이탈 가능성을 높이는 요인 (+ 계수)
- module_presentation_length: 모듈이 길수록 이탈 확률 증가
- my_average_score: 평균 점수가 높을수록 이탈 가능 ↑ : *이거 왜 이렇게 나왔는지 모르겠어요..*
- 특정과목, 과제 유형에서 이탈 가능성 증가 (code_module_GGG, assessment_type_TMA)

#### 📉 이탈 가능성을 낮추는 요인 (- 계수)
- disability: 장애 등록 학생은 오히려 이탈 확률이 낮다? (지원 제도가 있을 수 있음)
- my_score_trend: 점수가 상승 추세면 이탈 가능성 감소
- days_early_submission: 일찍 제출할수록 이탈 확률 낮음 → 참여도 높은 학생

### 💡 실질적인 인사이트
**개인 성취 지표(평균 점수, 조기 제출, 점수 추세 등)는 이탈 예측에 큰 영향**
**수강 과목 코드, 세션(2014B, 2013J 등)** 도 이탈과 밀접
**이탈 가능성이 높은 학생의 특징**
- 높은 평균 점수
- 모듈 기간이 긴 강의
- 특정 과목 코드(GGG 등)


### 2-1. KNN - K vs F1 Score 그래프
![스크린샷 2025-04-01 113114](https://github.com/user-attachments/assets/419883bb-67c2-4355-b549-0937391fcdac)

**KNN의 하이퍼파라미터 K 값에 따라 모델 성능(F1 Score)의 변화**

### ✅ 주요 포인트:
- K=1일 때 F1 Score가 가장 높음 (~0.825) → 과적합일 가능성 있음 (noise까지 학습)
- K=3~7 구간은 상대적으로 안정적이고 높음 → 적절한 K 후보
- K가 커질수록 성능이 점점 떨어짐 → 너무 많은 이웃을 보게 되면 결정 경계가 흐려짐

### 결론
최적의 K는 1~7 사이

### 2-2. KNN - PCA로 KNN 분포 시각화
![image](https://github.com/user-attachments/assets/f1b14eda-bd4a-4789-bef2-db15512d8d67)
✅ 1. 두 클래스가 전반적으로 섞여 있음
완전히 분리되는 영역 없음 → **데이터 자체가 선형 또는 완벽히 분리되지는 않음**
특히 중앙~오른쪽 영역에서는 빨강/파랑이 상당히 섞여 있음 → 예측이 어렵다는 뜻

✅ 2. 왼쪽 상단, 아래쪽은 상대적으로 파랑(비이탈)이 많음
특정 PCA 영역에 한쪽 클래스 비중이 높은 경우, 그 부분은 예측 정확도 높을 가능성 있음 (이탈 아님 구역)

✅ 3. 클러스터 구조는 분명히 존재
점들이 무작위로 퍼진 게 아니라, 몇 개의 덩어리(군집) 형성

이는 **비지도 학습(k-means 등)**이나 클러스터 기반 위험군 분석 가능성도 시사

✅ 4. 모델의 한계도 함께 보임
모델이 PCA 기준으로 봤을 때 이탈자와 비이탈자를 완벽히 분리해내지 못함

→ **비선형 분류기(XGBoost, SVM with kernel)**가 더 잘 작동할 수도 있음

### 3-1. XGBoost - 내장 Feature Importance (모델이 예측에 있어 어떤 feature를 얼마나 자주 사용했는지)
![image](https://github.com/user-attachments/assets/74b0fe15-6710-4e38-8455-708e02bafb56)
## ✅ 1위: my_score_std (11693번 사용) - 학생 점수의 표준편차
→ 점수의 변동성이 이탈 여부 예측에 가장 중요한 피처
💡 **점수가 들쭉날쭉한 학생일수록 이탈 위험이 높을 수 있음**
## ✅ 2위: my_average_score (11681) - 학생의 평균 점수
→ 성적 수준 자체도 강력한 신호
**성적이 너무 낮거나 높아도 이탈과 관련 있을 수 있음**

## ✅ 3위: date_registration (10862) - 수업 등록 시기
**→ 늦게 등록한 학생일수록 이탈 확률이 높다는 경향성을 포착했을 수 있음**

### 3-2. XGBoost - SHAP (모든 feature가 결과에 얼마나 기여했는지 수치화)
![스크린샷 2025-04-01 114517](https://github.com/user-attachments/assets/95131b70-1fee-4c7b-a863-e726fe761ba0)

## ✅ my_average_score<br/>
전체적으로 값이 낮으면(파랑) → SHAP 값이 양수 쪽<br/>
→ 평균 점수가 낮을수록 이탈 확률을 높임, 반대로 평균 점수가 높으면 → 이탈 가능성 낮음<br/>
## ✅ my_late_rate, course_late_rate <br/>
늦게 제출한 비율이 높을수록 (빨강) → SHAP 값 양수 → 이탈 확률 증가 → 시간 관리가 이탈 예측에 중요하다는 뜻!<br/>
## ✅ my_score_std<br/> <br/>
점수 편차가 높을수록 (빨강) → 점수 변동성이 클수록 이탈 확률이 높음<br/>
## ✅assessment_weight, weighted_score, course_avg_score <br/>
성취 수준이나 과제 비중도 이탈 여부에 복합적인 영향을 주고 있음 <br/>
ex: weighted_score가 높을수록 SHAP 값이 음수 → 이탈 가능성 줄임 <br/>

### 요약
**낮은 평균 점수, 높은 점수 변동성, 과제 지각률 → 이탈 확률 ↑** 
**조기 제출, 높은 성적, 일찍 등록 → 이탈 확률 ↓**
(색상은 각 데이터 포인트의 해당 피처 값, 점의 위치는 이탈에 준 영향!!!단순 중요도 순서가 아니라, "어떻게 영향을 주는지"까지 설명해주는 해석 도구임)







![image](https://github.com/user-attachments/assets/2b969f3e-f92d-4dfa-a459-dd3766a8d3cd)
![image](https://github.com/user-attachments/assets/75e3c05c-d535-4de5-92af-4f6fe19beb53)
Recall이 0.28 → 0.87로 크게 상승
→ 이탈자를 훨씬 더 잘 잡아냄 (실제 이탈자 중 예측된 비율이 상승)

Precision은 감소했지만 자연스러운 현상
→ 이탈자 예측을 더 공격적으로 시도했기 때문 (false positive 증가)

F1-score는 약간 하락했지만,
→ 전체적인 목표가 ‘이탈자를 놓치지 않는 것’이라면 매우 유의미한 개선.

Accuracy는 줄었지만 이는 클래스 불균형 완화로 인한 변화
→ 전체 정확도보다 이탈자 예측 성능이 더 중요한 상황에서는 좋은 방향





